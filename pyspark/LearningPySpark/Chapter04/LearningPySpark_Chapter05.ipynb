{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"},"colab":{"name":"LearningPySpark_Chapter05.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"-Rb6gP0I6HYP"},"source":["# Introducing MLib package of PySpark "]},{"cell_type":"markdown","metadata":{"id":"EhiaVEyl6HYS"},"source":["## Load and transform the data"]},{"cell_type":"markdown","metadata":{"id":"qPH1ZVbW6HYS"},"source":["Just like in the previous chapter, we first specify the schema of our dataset."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZFLdOEWe6JNJ","executionInfo":{"status":"ok","timestamp":1633115322864,"user_tz":420,"elapsed":39994,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"82164da2-8f14-49a6-8cd6-8d67ec6ecdcd"},"source":["!pip install pyspark"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.1.2.tar.gz (212.4 MB)\n","\u001b[K     |████████████████████████████████| 212.4 MB 63 kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 64.7 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=adabe3437ad19c86efc33d63eb149a611e2109504d02981d7aba1ee2d2b4cbdd\n","  Stored in directory: /root/.cache/pip/wheels/a5/0a/c1/9561f6fecb759579a7d863dcd846daaa95f598744e71b02c77\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.2\n"]}]},{"cell_type":"code","metadata":{"id":"GfB_daOB6I5D","executionInfo":{"status":"ok","timestamp":1633115348690,"user_tz":420,"elapsed":215,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["import pyspark\n","from pyspark.sql import SparkSession"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"6G5JmsH76P4h","executionInfo":{"status":"ok","timestamp":1633115358003,"user_tz":420,"elapsed":7530,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["spark = SparkSession.builder.appName('Learning PySpark').getOrCreate()\n","sc=spark.sparkContext"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJVZPKea6UG0","executionInfo":{"status":"ok","timestamp":1633115381194,"user_tz":420,"elapsed":23194,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"cbe1568f-c651-4ae7-fde6-4104a453fe39"},"source":["from google.colab import drive\n","drive.mount('/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /drive\n"]}]},{"cell_type":"code","metadata":{"collapsed":true,"id":"dBH9pBke6HYT","executionInfo":{"status":"ok","timestamp":1633115420700,"user_tz":420,"elapsed":141,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["import pyspark.sql.types as typ\n","\n","labels = [\n","    ('INFANT_ALIVE_AT_REPORT', typ.StringType()),\n","    ('BIRTH_YEAR', typ.IntegerType()),\n","    ('BIRTH_MONTH', typ.IntegerType()),\n","    ('BIRTH_PLACE', typ.StringType()),\n","    ('MOTHER_AGE_YEARS', typ.IntegerType()),\n","    ('MOTHER_RACE_6CODE', typ.StringType()),\n","    ('MOTHER_EDUCATION', typ.StringType()),\n","    ('FATHER_COMBINED_AGE', typ.IntegerType()),\n","    ('FATHER_EDUCATION', typ.StringType()),\n","    ('MONTH_PRECARE_RECODE', typ.StringType()),\n","    ('CIG_BEFORE', typ.IntegerType()),\n","    ('CIG_1_TRI', typ.IntegerType()),\n","    ('CIG_2_TRI', typ.IntegerType()),\n","    ('CIG_3_TRI', typ.IntegerType()),\n","    ('MOTHER_HEIGHT_IN', typ.IntegerType()),\n","    ('MOTHER_BMI_RECODE', typ.IntegerType()),\n","    ('MOTHER_PRE_WEIGHT', typ.IntegerType()),\n","    ('MOTHER_DELIVERY_WEIGHT', typ.IntegerType()),\n","    ('MOTHER_WEIGHT_GAIN', typ.IntegerType()),\n","    ('DIABETES_PRE', typ.StringType()),\n","    ('DIABETES_GEST', typ.StringType()),\n","    ('HYP_TENS_PRE', typ.StringType()),\n","    ('HYP_TENS_GEST', typ.StringType()),\n","    ('PREV_BIRTH_PRETERM', typ.StringType()),\n","    ('NO_RISK', typ.StringType()),\n","    ('NO_INFECTIONS_REPORTED', typ.StringType()),\n","    ('LABOR_IND', typ.StringType()),\n","    ('LABOR_AUGM', typ.StringType()),\n","    ('STEROIDS', typ.StringType()),\n","    ('ANTIBIOTICS', typ.StringType()),\n","    ('ANESTHESIA', typ.StringType()),\n","    ('DELIV_METHOD_RECODE_COMB', typ.StringType()),\n","    ('ATTENDANT_BIRTH', typ.StringType()),\n","    ('APGAR_5', typ.IntegerType()),\n","    ('APGAR_5_RECODE', typ.StringType()),\n","    ('APGAR_10', typ.IntegerType()),\n","    ('APGAR_10_RECODE', typ.StringType()),\n","    ('INFANT_SEX', typ.StringType()),\n","    ('OBSTETRIC_GESTATION_WEEKS', typ.IntegerType()),\n","    ('INFANT_WEIGHT_GRAMS', typ.IntegerType()),\n","    ('INFANT_ASSIST_VENTI', typ.StringType()),\n","    ('INFANT_ASSIST_VENTI_6HRS', typ.StringType()),\n","    ('INFANT_NICU_ADMISSION', typ.StringType()),\n","    ('INFANT_SURFACANT', typ.StringType()),\n","    ('INFANT_ANTIBIOTICS', typ.StringType()),\n","    ('INFANT_SEIZURES', typ.StringType()),\n","    ('INFANT_NO_ABNORMALITIES', typ.StringType()),\n","    ('INFANT_ANCEPHALY', typ.StringType()),\n","    ('INFANT_MENINGOMYELOCELE', typ.StringType()),\n","    ('INFANT_LIMB_REDUCTION', typ.StringType()),\n","    ('INFANT_DOWN_SYNDROME', typ.StringType()),\n","    ('INFANT_SUSPECTED_CHROMOSOMAL_DISORDER', typ.StringType()),\n","    ('INFANT_NO_CONGENITAL_ANOMALIES_CHECKED', typ.StringType()),\n","    ('INFANT_BREASTFED', typ.StringType())\n","]\n","\n","schema = typ.StructType([\n","        typ.StructField(e[0], e[1], False) for e in labels\n","    ])"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8BBC2vDZ6HYU"},"source":["Next, we load the data."]},{"cell_type":"code","metadata":{"id":"Pu4K1qmc6HYV","executionInfo":{"status":"ok","timestamp":1633115538738,"user_tz":420,"elapsed":3647,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["births = spark.read.csv('/drive/My Drive/Colab Notebooks/pyspark/LearningPySpark/Learning-PySpark-master/Data/births_train.csv', \n","                        header=True, \n","                        schema=schema)"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"G1fC6Iru6HYV"},"source":["Specify our recode dictionary."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"fhc4DfXd6HYW","executionInfo":{"status":"ok","timestamp":1633115546254,"user_tz":420,"elapsed":143,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["recode_dictionary = {\n","    'YNU': {\n","        'Y': 1,\n","        'N': 0,\n","        'U': 0\n","    }\n","}"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iqijn6C-6HYW"},"source":["Our goal is to predict whether the `'INFANT_ALIVE_AT_REPORT'` is either 1 or 0. Thus, we will drop all of the features that relate to the infant."]},{"cell_type":"code","metadata":{"id":"qF41BV8n6HYX","executionInfo":{"status":"ok","timestamp":1633115562964,"user_tz":420,"elapsed":604,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["selected_features = [\n","    'INFANT_ALIVE_AT_REPORT', \n","    'BIRTH_PLACE', \n","    'MOTHER_AGE_YEARS', \n","    'FATHER_COMBINED_AGE', \n","    'CIG_BEFORE', \n","    'CIG_1_TRI', \n","    'CIG_2_TRI', \n","    'CIG_3_TRI', \n","    'MOTHER_HEIGHT_IN', \n","    'MOTHER_PRE_WEIGHT', \n","    'MOTHER_DELIVERY_WEIGHT', \n","    'MOTHER_WEIGHT_GAIN', \n","    'DIABETES_PRE', \n","    'DIABETES_GEST', \n","    'HYP_TENS_PRE', \n","    'HYP_TENS_GEST', \n","    'PREV_BIRTH_PRETERM'\n","]\n","\n","births_trimmed = births.select(selected_features)"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ul9Rs2Jy6HYX"},"source":["Specify the recoding methods."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"9rj9FdIU6HYY","executionInfo":{"status":"ok","timestamp":1633115569634,"user_tz":420,"elapsed":147,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["import pyspark.sql.functions as func\n","\n","def recode(col, key):        \n","    return recode_dictionary[key][col] \n","\n","def correct_cig(feat):\n","    return func \\\n","        .when(func.col(feat) != 99, func.col(feat))\\\n","        .otherwise(0)\n","\n","rec_integer = func.udf(recode, typ.IntegerType())"],"execution_count":10,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r0KIN5sq6HYY"},"source":["Correct the features related to the number of smoked cigarettes."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"SFT2dSXj6HYY","executionInfo":{"status":"ok","timestamp":1633115573387,"user_tz":420,"elapsed":740,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["births_transformed = births_trimmed \\\n","    .withColumn('CIG_BEFORE', correct_cig('CIG_BEFORE'))\\\n","    .withColumn('CIG_1_TRI', correct_cig('CIG_1_TRI'))\\\n","    .withColumn('CIG_2_TRI', correct_cig('CIG_2_TRI'))\\\n","    .withColumn('CIG_3_TRI', correct_cig('CIG_3_TRI'))"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pH4i592k6HYZ"},"source":["Figure out which Yes/No/Unknown features are."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"EBm0AlvK6HYZ","executionInfo":{"status":"ok","timestamp":1633115619066,"user_tz":420,"elapsed":37227,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["cols = [(col.name, col.dataType) for col in births_trimmed.schema]\n","\n","YNU_cols = []\n","\n","for i, s in enumerate(cols):\n","    if s[1] == typ.StringType():\n","        dis = births.select(s[0]) \\\n","            .distinct() \\\n","            .rdd \\\n","            .map(lambda row: row[0]) \\\n","            .collect()\n","\n","        if 'Y' in dis:\n","            YNU_cols.append(s[0])"],"execution_count":12,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"j561UDip6HYZ"},"source":["DataFrames can transform the features *in bulk* while selecting features."]},{"cell_type":"code","metadata":{"id":"S8WNPmsW6HYZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633115653592,"user_tz":420,"elapsed":1098,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"0f5a3c28-63a0-4359-f33b-bf7f44b53e6f"},"source":["births.select([\n","        'INFANT_NICU_ADMISSION', \n","        rec_integer(\n","            'INFANT_NICU_ADMISSION', func.lit('YNU')\n","        ) \\\n","        .alias('INFANT_NICU_ADMISSION_RECODE')]\n","     ).take(5)"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n"," Row(INFANT_NICU_ADMISSION='Y', INFANT_NICU_ADMISSION_RECODE=1),\n"," Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0),\n"," Row(INFANT_NICU_ADMISSION='N', INFANT_NICU_ADMISSION_RECODE=0),\n"," Row(INFANT_NICU_ADMISSION='U', INFANT_NICU_ADMISSION_RECODE=0)]"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"hHCWMz1f6HYa"},"source":["Transform all the `YNU_cols` in one using a list of transformations."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"TgekKkdk6HYa","executionInfo":{"status":"ok","timestamp":1633115667590,"user_tz":420,"elapsed":295,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["exprs_YNU = [\n","    rec_integer(x, func.lit('YNU')).alias(x) \n","    if x in YNU_cols \n","    else x \n","    for x in births_transformed.columns\n","]\n","\n","births_transformed = births_transformed.select(exprs_YNU)"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jByWTAar6HYb"},"source":["Let's check if we got it correctly."]},{"cell_type":"code","metadata":{"id":"zaj9iDNZ6HYb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633115671231,"user_tz":420,"elapsed":791,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"507c8d38-4f81-406c-90dd-3ffdaecc69c4"},"source":["births_transformed.select(YNU_cols[-5:]).show(5)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["+------------+-------------+------------+-------------+------------------+\n","|DIABETES_PRE|DIABETES_GEST|HYP_TENS_PRE|HYP_TENS_GEST|PREV_BIRTH_PRETERM|\n","+------------+-------------+------------+-------------+------------------+\n","|           0|            0|           0|            0|                 0|\n","|           0|            0|           0|            0|                 0|\n","|           0|            0|           0|            0|                 0|\n","|           0|            0|           0|            0|                 1|\n","|           0|            0|           0|            0|                 0|\n","+------------+-------------+------------+-------------+------------------+\n","only showing top 5 rows\n","\n"]}]},{"cell_type":"markdown","metadata":{"id":"8wKcDgCR6HYb"},"source":["## Get to know your data"]},{"cell_type":"markdown","metadata":{"id":"ypWF7tlZ6HYb"},"source":["### Descriptive statistics"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"EqaUWXK76HYc"},"source":["We will use the `colStats(...)` method."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHChunt96HYc","executionInfo":{"status":"ok","timestamp":1633115681794,"user_tz":420,"elapsed":3135,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"6ece53ec-816f-4591-b906-43a3dc23d15f"},"source":["import pyspark.mllib.stat as st\n","import numpy as np\n","\n","numeric_cols = ['MOTHER_AGE_YEARS','FATHER_COMBINED_AGE',\n","                'CIG_BEFORE','CIG_1_TRI','CIG_2_TRI','CIG_3_TRI',\n","                'MOTHER_HEIGHT_IN','MOTHER_PRE_WEIGHT',\n","                'MOTHER_DELIVERY_WEIGHT','MOTHER_WEIGHT_GAIN'\n","               ]\n","\n","numeric_rdd = births_transformed\\\n","                       .select(numeric_cols)\\\n","                       .rdd \\\n","                       .map(lambda row: [e for e in row])\n","\n","mllib_stats = st.Statistics.colStats(numeric_rdd)\n","\n","for col, m, v in zip(numeric_cols, \n","                     mllib_stats.mean(), \n","                     mllib_stats.variance()):\n","    print('{0}: \\t{1:.2f} \\t {2:.2f}'.format(col, m, np.sqrt(v)))"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["MOTHER_AGE_YEARS: \t28.30 \t 6.08\n","FATHER_COMBINED_AGE: \t44.55 \t 27.55\n","CIG_BEFORE: \t1.43 \t 5.18\n","CIG_1_TRI: \t0.91 \t 3.83\n","CIG_2_TRI: \t0.70 \t 3.31\n","CIG_3_TRI: \t0.58 \t 3.11\n","MOTHER_HEIGHT_IN: \t65.12 \t 6.45\n","MOTHER_PRE_WEIGHT: \t214.50 \t 210.21\n","MOTHER_DELIVERY_WEIGHT: \t223.63 \t 180.01\n","MOTHER_WEIGHT_GAIN: \t30.74 \t 26.23\n"]}]},{"cell_type":"markdown","metadata":{"id":"kbDzyV3h6HYc"},"source":["For the categorical variables we will calculate the frequencies of their values."]},{"cell_type":"code","metadata":{"id":"ClsORjyx6HYc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633115706817,"user_tz":420,"elapsed":9790,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"7446e7cc-7397-48a7-d37b-fa6c465ab72d"},"source":["categorical_cols = [e for e in births_transformed.columns \n","                    if e not in numeric_cols]\n","\n","categorical_rdd = births_transformed\\\n","                       .select(categorical_cols)\\\n","                       .rdd \\\n","                       .map(lambda row: [e for e in row])\n","            \n","for i, col in enumerate(categorical_cols):\n","    agg = categorical_rdd \\\n","        .groupBy(lambda row: row[i]) \\\n","        .map(lambda row: (row[0], len(row[1])))\n","        \n","    print(col, sorted(agg.collect(), \n","                      key=lambda el: el[1], \n","                      reverse=True))"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["INFANT_ALIVE_AT_REPORT [(1, 23349), (0, 22080)]\n","BIRTH_PLACE [('1', 44558), ('4', 327), ('3', 224), ('2', 136), ('7', 91), ('5', 74), ('6', 11), ('9', 8)]\n","DIABETES_PRE [(0, 44881), (1, 548)]\n","DIABETES_GEST [(0, 43451), (1, 1978)]\n","HYP_TENS_PRE [(0, 44348), (1, 1081)]\n","HYP_TENS_GEST [(0, 43302), (1, 2127)]\n","PREV_BIRTH_PRETERM [(0, 43088), (1, 2341)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"zOD4GOys6HYc"},"source":["### Correlations"]},{"cell_type":"markdown","metadata":{"id":"8I9M9HgE6HYc"},"source":["Correlations between our features."]},{"cell_type":"code","metadata":{"id":"UIIBt1sG6HYd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633115723433,"user_tz":420,"elapsed":4505,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"841b0748-e00d-4a8a-c2f7-7fedef1c8528"},"source":["corrs = st.Statistics.corr(numeric_rdd)\n","\n","for i, el in enumerate(corrs > 0.5):\n","    correlated = [\n","        (numeric_cols[j], corrs[i][j]) \n","        for j, e in enumerate(el) \n","        if e == 1.0 and j != i]\n","    \n","    if len(correlated) > 0:\n","        for e in correlated:\n","            print('{0}-to-{1}: {2:.2f}' \\\n","                  .format(numeric_cols[i], e[0], e[1]))"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["CIG_BEFORE-to-CIG_1_TRI: 0.83\n","CIG_BEFORE-to-CIG_2_TRI: 0.72\n","CIG_BEFORE-to-CIG_3_TRI: 0.62\n","CIG_1_TRI-to-CIG_BEFORE: 0.83\n","CIG_1_TRI-to-CIG_2_TRI: 0.87\n","CIG_1_TRI-to-CIG_3_TRI: 0.76\n","CIG_2_TRI-to-CIG_BEFORE: 0.72\n","CIG_2_TRI-to-CIG_1_TRI: 0.87\n","CIG_2_TRI-to-CIG_3_TRI: 0.89\n","CIG_3_TRI-to-CIG_BEFORE: 0.62\n","CIG_3_TRI-to-CIG_1_TRI: 0.76\n","CIG_3_TRI-to-CIG_2_TRI: 0.89\n","MOTHER_PRE_WEIGHT-to-MOTHER_DELIVERY_WEIGHT: 0.54\n","MOTHER_PRE_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.65\n","MOTHER_DELIVERY_WEIGHT-to-MOTHER_PRE_WEIGHT: 0.54\n","MOTHER_DELIVERY_WEIGHT-to-MOTHER_WEIGHT_GAIN: 0.60\n","MOTHER_WEIGHT_GAIN-to-MOTHER_PRE_WEIGHT: 0.65\n","MOTHER_WEIGHT_GAIN-to-MOTHER_DELIVERY_WEIGHT: 0.60\n"]}]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"35pfkPJa6HYd"},"source":["We can drop most of highly correlated features. "]},{"cell_type":"code","metadata":{"id":"Df-_8ycB6HYd","executionInfo":{"status":"ok","timestamp":1633115731897,"user_tz":420,"elapsed":143,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["features_to_keep = [\n","    'INFANT_ALIVE_AT_REPORT', \n","    'BIRTH_PLACE', \n","    'MOTHER_AGE_YEARS', \n","    'FATHER_COMBINED_AGE', \n","    'CIG_1_TRI', \n","    'MOTHER_HEIGHT_IN', \n","    'MOTHER_PRE_WEIGHT', \n","    'DIABETES_PRE', \n","    'DIABETES_GEST', \n","    'HYP_TENS_PRE', \n","    'HYP_TENS_GEST', \n","    'PREV_BIRTH_PRETERM'\n","]\n","births_transformed = births_transformed.select([e for e in features_to_keep])"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w-jHqb8-Suoy","executionInfo":{"status":"ok","timestamp":1633115912428,"user_tz":420,"elapsed":436,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"49cc0b3e-b9ed-40a3-c976-3d24077feca3"},"source":["births_transformed.take(10)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=29, FATHER_COMBINED_AGE=99, CIG_1_TRI=0, MOTHER_HEIGHT_IN=99, MOTHER_PRE_WEIGHT=999, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=22, FATHER_COMBINED_AGE=29, CIG_1_TRI=0, MOTHER_HEIGHT_IN=65, MOTHER_PRE_WEIGHT=180, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=38, FATHER_COMBINED_AGE=40, CIG_1_TRI=0, MOTHER_HEIGHT_IN=63, MOTHER_PRE_WEIGHT=155, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=39, FATHER_COMBINED_AGE=42, CIG_1_TRI=0, MOTHER_HEIGHT_IN=60, MOTHER_PRE_WEIGHT=128, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=1),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=18, FATHER_COMBINED_AGE=99, CIG_1_TRI=4, MOTHER_HEIGHT_IN=61, MOTHER_PRE_WEIGHT=110, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=32, FATHER_COMBINED_AGE=37, CIG_1_TRI=0, MOTHER_HEIGHT_IN=66, MOTHER_PRE_WEIGHT=150, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=22, FATHER_COMBINED_AGE=25, CIG_1_TRI=0, MOTHER_HEIGHT_IN=68, MOTHER_PRE_WEIGHT=155, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=25, FATHER_COMBINED_AGE=26, CIG_1_TRI=0, MOTHER_HEIGHT_IN=64, MOTHER_PRE_WEIGHT=136, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=26, FATHER_COMBINED_AGE=32, CIG_1_TRI=0, MOTHER_HEIGHT_IN=64, MOTHER_PRE_WEIGHT=140, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0),\n"," Row(INFANT_ALIVE_AT_REPORT=0, BIRTH_PLACE='1', MOTHER_AGE_YEARS=39, FATHER_COMBINED_AGE=66, CIG_1_TRI=0, MOTHER_HEIGHT_IN=65, MOTHER_PRE_WEIGHT=140, DIABETES_PRE=0, DIABETES_GEST=0, HYP_TENS_PRE=0, HYP_TENS_GEST=0, PREV_BIRTH_PRETERM=0)]"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"hlfY1dwO6HYd"},"source":["### Statistical testing"]},{"cell_type":"markdown","metadata":{"collapsed":false,"id":"UkgmUK7u6HYd"},"source":["Run a Chi-square test to determine if there are significant differences for categorical variables."]},{"cell_type":"code","metadata":{"id":"4buQrVYS6HYd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1633115986526,"user_tz":420,"elapsed":45047,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"0ce76ff2-a38e-499b-f285-0b716752cb2f"},"source":["import pyspark.mllib.linalg as ln\n","\n","for cat in categorical_cols[1:]:\n","    agg = births_transformed \\\n","        .groupby('INFANT_ALIVE_AT_REPORT') \\\n","        .pivot(cat) \\\n","        .count()    \n","\n","    agg_rdd = agg \\\n","        .rdd\\\n","        .map(lambda row: (row[1:])) \\\n","        .flatMap(lambda row: \n","                 [0 if e == None else e for e in row]) \\\n","        .collect()\n","\n","    row_length = len(agg.collect()[0]) - 1\n","    agg = ln.Matrices.dense(row_length, 2, agg_rdd)\n","    \n","    test = st.Statistics.chiSqTest(agg)\n","    print(cat, round(test.pValue, 4))"],"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["BIRTH_PLACE 0.0\n","DIABETES_PRE 0.0\n","DIABETES_GEST 0.0\n","HYP_TENS_PRE 0.0\n","HYP_TENS_GEST 0.0\n","PREV_BIRTH_PRETERM 0.0\n"]}]},{"cell_type":"markdown","metadata":{"id":"JjjhXxbH6HYe"},"source":["## Create the final dataset"]},{"cell_type":"markdown","metadata":{"id":"DPUV0u4d6HYe"},"source":["### Create an RDD of `LabeledPoint`s\n","\n","We will use a hashing trick to encode the `'BIRTH_PLACE'` feature."]},{"cell_type":"code","metadata":{"id":"LKtkF0Oi6HYe","executionInfo":{"status":"ok","timestamp":1633115820372,"user_tz":420,"elapsed":151,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["import pyspark.mllib.feature as ft\n","import pyspark.mllib.regression as reg\n","\n","hashing = ft.HashingTF(7)\n","\n","births_hashed = births_transformed \\\n","    .rdd \\\n","    .map(lambda row: [\n","            list(hashing.transform(row[1]).toArray()) \n","                if col == 'BIRTH_PLACE' \n","                else row[i] \n","            for i, col \n","            in enumerate(features_to_keep)]) \\\n","    .map(lambda row: [[e] if type(e) == int else e \n","                      for e in row]) \\\n","    .map(lambda row: [item for sublist in row \n","                      for item in sublist]) \\\n","    .map(lambda row: reg.LabeledPoint(\n","            row[0], \n","            ln.Vectors.dense(row[1:]))\n","        )"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"STRDmFsg6HYe"},"source":["### Split into training and testing"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"VsgUAhD16HYe"},"source":["Before we move to the modeling stage, we need to split our dataset into two sets: one we'll use for training and another one for testing."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"PxLOJeuA6HYe","executionInfo":{"status":"ok","timestamp":1633115825801,"user_tz":420,"elapsed":138,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["births_train, births_test = births_hashed.randomSplit([0.6, 0.4])"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ksqiptix6HYe"},"source":["## Predicting infant survival"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"tvtoFGSV6HYe"},"source":["### Logistic regression in Spark\n","\n","MLLib used to provide a logistic regression model estimated using a stochastic gradient descent (SGD) algorithm. This model has been deprecated in Spark 2.0 in favor of the `LogisticRegressionWithLBFGS` model. "]},{"cell_type":"code","metadata":{"id":"35Y3Z5-16HYf","executionInfo":{"status":"ok","timestamp":1633115842287,"user_tz":420,"elapsed":9858,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["from pyspark.mllib.classification \\\n","    import LogisticRegressionWithLBFGS\n","\n","LR_Model = LogisticRegressionWithLBFGS \\\n","    .train(births_train, iterations=10)"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zK2V4eGZ6HYf"},"source":["Let's now use the model to predict the classes for our testing set."]},{"cell_type":"code","metadata":{"collapsed":true,"id":"w6Tp93zu6HYf","executionInfo":{"status":"ok","timestamp":1633115847927,"user_tz":420,"elapsed":145,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["LR_results = (\n","        births_test.map(lambda row: row.label) \\\n","        .zip(LR_Model \\\n","             .predict(births_test\\\n","                      .map(lambda row: row.features)))\n","    ).map(lambda row: (row[0], row[1] * 1.0))"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fCVp2iU_6HYf"},"source":["Let's check how well or how bad our model performed."]},{"cell_type":"code","metadata":{"id":"yNzeylO36HYf","colab":{"base_uri":"https://localhost:8080/","height":749},"executionInfo":{"status":"error","timestamp":1633115852457,"user_tz":420,"elapsed":2132,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"44fddc9b-a75c-4023-efcb-cb05bb582ea1"},"source":["import pyspark.mllib.evaluation as ev\n","LR_evaluation = ev.BinaryClassificationMetrics(LR_results)\n","\n","print('Area under PR: {0:.2f}' \\\n","      .format(LR_evaluation.areaUnderPR))\n","print('Area under ROC: {0:.2f}' \\\n","      .format(LR_evaluation.areaUnderROC))\n","LR_evaluation.unpersist()"],"execution_count":25,"outputs":[{"output_type":"error","ename":"PythonException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-ac43027f6c2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluation\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mLR_evaluation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryClassificationMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Area under PR: {0:.2f}'\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mareaUnderPR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Area under ROC: {0:.2f}'\u001b[0m       \u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLR_evaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mareaUnderROC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/mllib/evaluation.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, scoreAndLabels)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscoreAndLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0msql_ctx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mnumCol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoreAndLabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         schema = StructType([\n\u001b[1;32m     65\u001b[0m             \u001b[0mStructField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDoubleType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnullable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \"\"\"\n\u001b[0;32m-> 1586\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-10-f151e23e4891>\", line 4, in recode\nKeyError: '7'\n"]}]},{"cell_type":"markdown","metadata":{"id":"YB6UKW886HYf"},"source":["### Selecting only the most predictable features"]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"o4tCgz666HYf"},"source":["MLLib allows us to select the most predictable features using a Chi-Square selector."]},{"cell_type":"code","metadata":{"id":"RkrfQaUx6HYg","executionInfo":{"status":"ok","timestamp":1633116084011,"user_tz":420,"elapsed":5326,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}}},"source":["selector = ft.ChiSqSelector(4).fit(births_train)\n","\n","topFeatures_train = (\n","        births_train.map(lambda row: row.label) \\\n","        .zip(selector \\\n","             .transform(births_train \\\n","                        .map(lambda row: row.features)))\n","    ).map(lambda row: reg.LabeledPoint(row[0], row[1]))\n","\n","topFeatures_test = (\n","        births_test.map(lambda row: row.label) \\\n","        .zip(selector \\\n","             .transform(births_test \\\n","                        .map(lambda row: row.features)))\n","    ).map(lambda row: reg.LabeledPoint(row[0], row[1]))"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"collapsed":true,"id":"bt1bcd6B6HYg"},"source":["### Random Forest in Spark\n","\n","We are now ready to build the random forest model. "]},{"cell_type":"code","metadata":{"id":"688bS-bF6HYg","colab":{"base_uri":"https://localhost:8080/","height":715},"executionInfo":{"status":"error","timestamp":1633116096117,"user_tz":420,"elapsed":332,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"351c19bb-b890-47e9-e303-f098d51a5d98"},"source":["from pyspark.mllib.tree import RandomForest\n","\n","RF_model = RandomForest \\\n","    .trainClassifier(data=topFeatures_train, \n","                     numClasses=2, \n","                     categoricalFeaturesInfo={}, \n","                     numTrees=6,  \n","                     featureSubsetStrategy='all',\n","                     seed=666)"],"execution_count":31,"outputs":[{"output_type":"error","ename":"PythonException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-d62543ffe1ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                      \u001b[0mnumTrees\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                      \u001b[0mfeatureSubsetStrategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'all'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m                      seed=666)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/mllib/tree.py\u001b[0m in \u001b[0;36mtrainClassifier\u001b[0;34m(cls, data, numClasses, categoricalFeaturesInfo, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins, seed)\u001b[0m\n\u001b[1;32m    426\u001b[0m         return cls._train(data, \"classification\", numClasses,\n\u001b[1;32m    427\u001b[0m                           \u001b[0mcategoricalFeaturesInfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumTrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatureSubsetStrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimpurity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                           maxDepth, maxBins, seed)\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/mllib/tree.py\u001b[0m in \u001b[0;36m_train\u001b[0;34m(cls, data, algo, numClasses, categoricalFeaturesInfo, numTrees, featureSubsetStrategy, impurity, maxDepth, maxBins, seed)\u001b[0m\n\u001b[1;32m    319\u001b[0m     def _train(cls, data, algo, numClasses, categoricalFeaturesInfo, numTrees,\n\u001b[1;32m    320\u001b[0m                featureSubsetStrategy, impurity, maxDepth, maxBins, seed):\n\u001b[0;32m--> 321\u001b[0;31m         \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLabeledPoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"the data should be RDD of LabeledPoint\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeatureSubsetStrategy\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupportedFeatureSubsetStrategies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \"\"\"\n\u001b[0;32m-> 1586\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-10-f151e23e4891>\", line 4, in recode\nKeyError: '1'\n"]}]},{"cell_type":"markdown","metadata":{"id":"cU5Qgdlz6HYg"},"source":["Let's see how well our model did."]},{"cell_type":"code","metadata":{"id":"-iq8Z86e6HYg","colab":{"base_uri":"https://localhost:8080/","height":232},"executionInfo":{"status":"error","timestamp":1633116129924,"user_tz":420,"elapsed":133,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"a2911931-8fb2-415a-f939-d2330191fa22"},"source":["RF_results = (\n","        topFeatures_test.map(lambda row: row.label) \\\n","        .zip(RF_model \\\n","             .predict(topFeatures_test \\\n","                      .map(lambda row: row.features)))\n","    )\n","\n","RF_evaluation = ev.BinaryClassificationMetrics(RF_results)\n","\n","print('Area under PR: {0:.2f}' \\\n","      .format(RF_evaluation.areaUnderPR))\n","print('Area under ROC: {0:.2f}' \\\n","      .format(RF_evaluation.areaUnderROC))\n","RF_evaluation.unpersist()"],"execution_count":32,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-0f69ebfb5866>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m RF_results = (\n\u001b[1;32m      2\u001b[0m         \u001b[0mtopFeatures_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         .zip(RF_model \\\n\u001b[0m\u001b[1;32m      4\u001b[0m              .predict(topFeatures_test \\\n\u001b[1;32m      5\u001b[0m                       .map(lambda row: row.features)))\n","\u001b[0;31mNameError\u001b[0m: name 'RF_model' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"tV-M74IT6HYg"},"source":["Let's see how the logistic regression would perform with reduced number of features."]},{"cell_type":"code","metadata":{"id":"INqqWFMH6HYh","colab":{"base_uri":"https://localhost:8080/","height":749},"executionInfo":{"status":"error","timestamp":1633116138088,"user_tz":420,"elapsed":466,"user":{"displayName":"Raj Iyengar","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"14194838542243042437"}},"outputId":"6121ee56-2d9b-45f3-d844-5c88ec245853"},"source":["LR_Model_2 = LogisticRegressionWithLBFGS \\\n","    .train(topFeatures_train, iterations=10)\n","\n","LR_results_2 = (\n","        topFeatures_test.map(lambda row: row.label) \\\n","        .zip(LR_Model_2 \\\n","             .predict(topFeatures_test \\\n","                      .map(lambda row: row.features)))\n","    ).map(lambda row: (row[0], row[1] * 1.0))\n","\n","LR_evaluation_2 = ev.BinaryClassificationMetrics(LR_results_2)\n","\n","print('Area under PR: {0:.2f}' \\\n","      .format(LR_evaluation_2.areaUnderPR))\n","print('Area under ROC: {0:.2f}' \\\n","      .format(LR_evaluation_2.areaUnderROC))\n","LR_evaluation_2.unpersist()"],"execution_count":33,"outputs":[{"output_type":"error","ename":"PythonException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mPythonException\u001b[0m                           Traceback (most recent call last)","\u001b[0;32m<ipython-input-33-3d6c59210ad9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLR_Model_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegressionWithLBFGS\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopFeatures_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m LR_results_2 = (\n\u001b[1;32m      4\u001b[0m         \u001b[0mtopFeatures_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         .zip(LR_Model_2 \\\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/mllib/classification.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(cls, data, iterations, initialWeights, regParam, regType, intercept, corrections, tolerance, validateData, numClasses)\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitialWeights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnumClasses\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 415\u001b[0;31m                 \u001b[0minitialWeights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    416\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    417\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mintercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mfirst\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1584\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mRDD\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1585\u001b[0m         \"\"\"\n\u001b[0;32m-> 1586\u001b[0;31m         \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1588\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/rdd.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartsScanned\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnumPartsToTry\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotalParts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtakeUpToNumLeft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0mitems\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36mrunJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   1231\u001b[0m         \u001b[0;31m# SparkContext#runJob.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mmappedRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmapPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartitionFunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1233\u001b[0;31m         \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPythonRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunJob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmappedRDD\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jrdd_deserializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1305\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1307\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mPythonException\u001b[0m: \n  An exception was thrown from the Python worker. Please see the stack trace below.\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 604, in main\n    process()\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 596, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 211, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 132, in dump_stream\n    for obj in iterator:\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 200, in _batched\n    for item in iterator:\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 450, in <genexpr>\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 85, in <lambda>\n    return lambda *a: f(*a)\n  File \"/usr/local/lib/python3.7/dist-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 73, in wrapper\n    return f(*args, **kwargs)\n  File \"<ipython-input-10-f151e23e4891>\", line 4, in recode\nKeyError: '\\x05'\n"]}]}]}